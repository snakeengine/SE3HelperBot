# ğŸ“ lang.py
import json
import os
import threading

# ===== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¹Ø§Ù…Ø© =====
# Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡Ø§ ÙÙ‚Ø·
ALLOWED_LANGS = {"en", "ar"}

# ÙŠÙ…ÙƒÙ† Ø¶Ø¨Ø· Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø¹Ø¨Ø± .envØŒ ÙˆØ¥Ù† ÙƒØ§Ù†Øª Ù‚ÙŠÙ…Ø© ØºÙŠØ± Ù…Ø³Ù…ÙˆØ­Ø© â†’ "en"
_ENV_DEFAULT = os.getenv("DEFAULT_LANG", "en").strip().lower()
_DEFAULT_LANG = _ENV_DEFAULT if _ENV_DEFAULT in ALLOWED_LANGS else "en"

# Ù…Ø³Ø§Ø±Ø§Øª
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
LOCALES_DIR = os.path.join(BASE_DIR, "locales")
USER_LANG_FILE = os.path.join(BASE_DIR, "user_langs.json")

_LOCK = threading.RLock()
_translations: dict[str, dict] = {}
_known_langs: set[str] = set()  # Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ù…Ø­Ù…Ù‘Ù„Ø© ÙØ¹Ù„ÙŠÙ‹Ø§ Ù…Ù† ALLOWED_LANGS


def _atomic_write(path: str, data) -> None:
    os.makedirs(os.path.dirname(path), exist_ok=True)
    tmp = f"{path}.tmp"
    with open(tmp, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    os.replace(tmp, path)


def _normalize_lang(code: str | None) -> str:
    """
    ÙŠØ®ØªØ²Ù„ Ù…Ø«Ù„ 'en-US' â†’ 'en' ÙˆÙŠÙ‚ØµØ± Ø¹Ù„Ù‰ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡Ø§ ÙÙ‚Ø·.
    Ø£ÙŠ Ù‚ÙŠÙ…Ø© ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ© ØªÙØ¹Ø§Ø¯ÙÙ„ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ (_DEFAULT_LANG).
    """
    if not code:
        return _DEFAULT_LANG
    code = str(code).strip().lower()
    if "-" in code:
        code = code.split("-", 1)[0]
    # ØªØ·Ø¨ÙŠØ¹ Ø³Ø±ÙŠØ¹ Ù„Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
    if code.startswith("ar"):
        code = "ar"
    elif code.startswith("en"):
        code = "en"
    # Ø­ØµØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ù…ÙˆØ­
    return code if code in ALLOWED_LANGS else _DEFAULT_LANG


def load_translations() -> dict[str, dict]:
    """
    ØªØ­Ù…ÙŠÙ„ Ù…Ù„ÙØ§Øª locales/<lang>.json Ù„Ù„ØºØ§Øª Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡Ø§ ÙÙ‚Ø·.
    """
    translations: dict[str, dict] = {}
    if not os.path.isdir(LOCALES_DIR):
        return {_DEFAULT_LANG: {}}

    for filename in os.listdir(LOCALES_DIR):
        if not filename.endswith(".json"):
            continue
        lang_code = filename[:-5].strip().lower()
        if lang_code not in ALLOWED_LANGS:
            # Ù†ØªØ¬Ø§Ù‡Ù„ Ø£ÙŠ Ù…Ù„ÙØ§Øª ØºÙŠØ± en/ar Ø­ØªÙ‰ Ù„Ùˆ ÙˆØ¬Ø¯Øª Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯
            continue
        path = os.path.join(LOCALES_DIR, filename)
        try:
            with open(path, "r", encoding="utf-8") as f:
                data = json.load(f)
                if isinstance(data, dict):
                    translations[lang_code] = data
        except Exception:
            # ØªØ¬Ø§Ù‡Ù„ Ø£ÙŠ Ù…Ù„Ù ØªØ§Ù„Ù Ø¨Ø¯ÙˆÙ† ÙƒØ³Ø± Ø§Ù„ØªØ­Ù…ÙŠÙ„
            continue

    # ØªØ£ÙƒÙŠØ¯ ÙˆØ¬ÙˆØ¯ Ø®Ø±ÙŠØ·Ø© Ù„Ù„ØºØ© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
    translations.setdefault(_DEFAULT_LANG, {})
    return translations


def reload_locales() -> None:
    """Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„ Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ±Ø¬Ù…Ø© Ù…Ù† Ø§Ù„Ù‚Ø±Øµ (EN/AR ÙÙ‚Ø·)."""
    global _translations, _known_langs
    with _LOCK:
        _translations = load_translations()
        # Ù„Ø§ Ù†ÙØ¹Ù„Ù† Ø¥Ù„Ø§ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„ØªÙŠ ØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡Ø§ ÙØ¹Ù„ÙŠÙ‹Ø§
        _known_langs = set(_translations.keys()).intersection(ALLOWED_LANGS)


# ØªØ­Ù…ÙŠÙ„ Ø£ÙˆÙ„ÙŠ
reload_locales()


def available_languages() -> list[str]:
    """Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© ÙØ¹Ù„ÙŠÙ‹Ø§ (Ù…Ø­ØµÙˆØ±Ø© ÙÙŠ ALLOWED_LANGS)."""
    with _LOCK:
        langs = _known_langs or { _DEFAULT_LANG }
        return sorted(langs)


def t(lang_code: str, key: str) -> str:
    """
    ØªØ±Ø¬Ù…Ø© Ù…ÙØªØ§Ø­ Ù…Ø¹ fallback Ù„Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø«Ù… Ø§Ù„Ù…ÙØªØ§Ø­ Ù†ÙØ³Ù‡ Ø¥Ù† Ù„Ù… ÙŠÙˆØ¬Ø¯.
    """
    if not key:
        return ""
    lang_code = _normalize_lang(lang_code)
    with _LOCK:
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ù„ØºØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        lang_map = _translations.get(lang_code)
        if isinstance(lang_map, dict) and key in lang_map:
            val = lang_map.get(key)
            return val if isinstance(val, str) else key
        # ÙÙˆÙ„Ø¨Ø§Ùƒ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
        val = _translations.get("en", {}).get(key)
        return val if isinstance(val, str) else key


def tf(lang_code: str, key: str, **kwargs) -> str:
    """t() + format(**kwargs) Ù…Ø¹ fallback Ø¢Ù…Ù†."""
    try:
        return t(lang_code, key).format(**kwargs)
    except Exception:
        return t(lang_code, key)


def set_user_lang(user_id: int, lang_code: str):
    """
    Ø­ÙØ¸ Ù„ØºØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø´ÙƒÙ„ Ø°Ø±Ù‘ÙŠ. ØªÙØ¬Ø¨Ø± Ø§Ù„Ù‚ÙŠÙ… Ø¥Ù„Ù‰ ALLOWED_LANGS ÙÙ‚Ø·.
    """
    lang_code = _normalize_lang(lang_code)
    with _LOCK:
        # Ù„Ùˆ Ù…Ù„Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ØªØ§Ù„Ù Ù†Ø¨Ø¯Ø£ Ù…Ù† Ø¬Ø¯ÙŠØ¯
        try:
            with open(USER_LANG_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                if not isinstance(data, dict):
                    data = {}
        except FileNotFoundError:
            data = {}
        except Exception:
            data = {}
        # Ù„Ø§ Ù†Ø³Ø¬Ù‘Ù„ Ø¥Ù„Ø§ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„ØªÙŠ ØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡Ø§ ÙØ¹Ù„ÙŠÙ‹Ø§ØŒ ÙˆØ¥Ù„Ø§ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
        if lang_code not in _known_langs:
            lang_code = _DEFAULT_LANG
        data[str(user_id)] = lang_code
        _atomic_write(USER_LANG_FILE, data)


def get_user_lang(user_id: int) -> str:
    """
    Ø¬Ù„Ø¨ Ù„ØºØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…. ÙŠØ±Ø¬Ø¹ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù„Ùˆ ØºÙŠØ± Ù…Ø¹Ø±Ù‘Ù Ø£Ùˆ ØºÙŠØ± Ù…Ø­Ù…Ù‘Ù„.
    """
    try:
        with open(USER_LANG_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
            if isinstance(data, dict):
                lang_code = data.get(str(user_id))
                if isinstance(lang_code, str):
                    lc = _normalize_lang(lang_code)
                    return lc if lc in _known_langs else _DEFAULT_LANG
    except FileNotFoundError:
        pass
    except Exception:
        pass
    return _DEFAULT_LANG
